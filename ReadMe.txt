Implementation of a simple neural net whose end goal is to be trained to give the outputs of the XOR gate. The weights are updated during backpropagation using conjugate gradient descent. 


Each of beta values are one of the weights in the net, and the graph represents the final shape of the entire function. 


Run XORNeuralNet.py to see the functionality. 





